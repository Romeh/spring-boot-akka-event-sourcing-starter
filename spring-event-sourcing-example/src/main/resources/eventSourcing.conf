# This file provides a set of AKKA configuration for test scenario.

akka {

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "info"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
    deployment {
      # Use a wild dispatcher to take care for any actor.
      "/*" {
        router = round-robin-pool
        # Don't change below to anything higher than 1. For such needs duplicate another one with actor name as shown below.
        nr-of-instances = 1
      }
    }
    #allow-java-serialization = no
    serializers {
          myEventsAndCmdsSerializer = "com.romeh.ordermanager.serializer.OrderManagerSerializer"
    }
    serialization-bindings {
          "com.romeh.ordermanager.entities.commands.OrderCmd" = myEventsAndCmdsSerializer
          "com.romeh.ordermanager.entities.events.OrderEvent" = myEventsAndCmdsSerializer
    }
  }

 cluster.sharding {
    remember-entities = on
    journal-plugin-id = "akka.persistence.journal.leveldb"
    snapshot-plugin-id = "akka.persistence.snapshot-store.local"

  }
  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 3001
    }
  }

  cluster {
    seed-nodes = ["akka.tcp://orderManagerSystem@127.0.0.1:3001"]
    auto-down-unreachable-after = 10s
    metrics.enabled = off

  }
  extensions = ["akka.persistence.ignite.extension.IgniteExtensionProvider"]
//  # Level DB is goood for laptop based development.
//  persistence {
//      journal {
//       plugin = "akka.persistence.journal.leveldb"
//        leveldb {
//           dir = "target/example/journal"
//          native = false
//        }
//       }
//       snapshot-store {
//        plugin = "akka.persistence.snapshot-store.local"
//       local.dir = "target/example/snapshots"
//       }
//  }

  persistence.journal.plugin = "akka.persistence.journal.ignite"
  persistence.snapshot-store.plugin = "akka.persistence.snapshot.ignite"

}
ignite {
  isClientNode = false
  // for ONLY testing
  tcpDiscoveryAddresses = "localhost"
  metricsLogFrequency = 0
  // thread pools based into target machine specs
  queryThreadPoolSize = 4
  dataStreamerThreadPoolSize = 1
  managementThreadPoolSize = 2
  publicThreadPoolSize = 4
  systemThreadPoolSize = 2
  rebalanceThreadPoolSize = 1
  asyncCallbackPoolSize = 4
  peerClassLoadingEnabled = false
  enableFilePersistence = true
  igniteConnectorPort = 11211
  igniteServerPortRange = "47500..47509"
  ignitePersistenceFilePath = "./WriteData"
}

akka.log-config-on-start = false

akka.actor.default-dispatcher.default-executor.fallback = "thread-pool-executor"

# This dispatcher is being refered by Service when it creates actors.
task-runner-actor-dispatcher {

  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher

  # What kind of ExecutionService to use
  executor = "thread-pool-executor"

  # This will be used if you have set "executor = "thread-pool-executor""
  thread-pool-executor {

    # Keep alive time for threads
    keep-alive-time = 60s

    # Min number of threads to cap factor-based core number to
    core-pool-size-min = 8

    # The core pool size factor is used to determine thread pool core size
    # using the following formula: ceil(available processors * factor).
    # Resulting size is then bounded by the core-pool-size-min and
    # core-pool-size-max values.
    core-pool-size-factor = 3.0

    # Max number of threads to cap factor-based number to
    core-pool-size-max = 64

    # Minimum number of threads to cap factor-based max number to
    # (if using a bounded task queue)
    max-pool-size-min = 8

    # Max no of threads (if using a bounded task queue) is determined by
    # calculating: ceil(available processors * factor)
    max-pool-size-factor = 3.0

    # Max number of threads to cap factor-based max number to
    # (if using a  bounded task queue)
    max-pool-size-max = 64

    # Specifies the bounded capacity of the task queue (< 1 == unbounded)
    task-queue-size = -1

    # Specifies which type of task queue will be used, can be "array" or
    # "linked" (default)
    task-queue-type = "linked"

    # Allow core threads to time out
    allow-core-timeout = on
  }

  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 1
}